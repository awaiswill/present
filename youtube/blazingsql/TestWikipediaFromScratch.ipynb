{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 59 files\n",
      "Detected 48 cores.\n",
      "Using 48 threads\n",
      "100,000, files: 0\n",
      "200,000, files: 0\n",
      "300,000, files: 0\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as etree\n",
    "import multiprocessing as mp\n",
    "import bz2\n",
    "import codecs\n",
    "import csv\n",
    "import time\n",
    "import os,glob\n",
    "import traceback\n",
    "\n",
    "WIKIPEDIA_ROOT = \"/media/jeff/Data/data/wikipedia\"\n",
    "WIKIPEDIA_DL = os.path.join(WIKIPEDIA_ROOT, 'dl')\n",
    "WORKER_REPORT = 1000\n",
    "ENTIRE_TASK_REPORT = 100000\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "def strip_tag_name(t):\n",
    "    idx = k = t.rfind(\"}\")\n",
    "    if idx != -1:\n",
    "        t = t[idx + 1:]\n",
    "    return t\n",
    "\n",
    "class ExtractWikipedia:\n",
    "    def __init__(self, worker):\n",
    "        self.totalCount = 0\n",
    "        self.articleCount = 0\n",
    "        self.redirectCount = 0\n",
    "        self.templateCount = 0\n",
    "        self.worker = worker\n",
    "\n",
    "    def extract_file(self, path):\n",
    "        start_time = time.time()\n",
    "\n",
    "        title = None\n",
    "        redirect = \"\"\n",
    "        count = 0\n",
    "        with bz2.BZ2File(path, \"r\") as fp:\n",
    "            for event, elem in etree.iterparse(fp, events=('start', 'end')):\n",
    "                tname = strip_tag_name(elem.tag)\n",
    "\n",
    "                if event == 'start':\n",
    "                    if tname == 'page':\n",
    "                        title = ''\n",
    "                        id = -1\n",
    "                        redirect = ''\n",
    "                        inrevision = False\n",
    "                        ns = 0\n",
    "                    elif tname == 'revision':\n",
    "                        # Do not pick up on revision id's\n",
    "                        inrevision = True   \n",
    "                else:\n",
    "                    if tname == 'title':\n",
    "                        title = elem.text\n",
    "                    elif tname == 'id' and not inrevision:\n",
    "                        id = int(elem.text)\n",
    "                    elif tname == 'redirect':\n",
    "                        redirect = elem.attrib['title']\n",
    "                    elif tname == 'ns':\n",
    "                        ns = int(elem.text)\n",
    "                    elif tname == 'page':\n",
    "                        self.totalCount += 1\n",
    "\n",
    "                        if ns == 10:\n",
    "                            self.templateCount += 1\n",
    "                            self.worker.process_template(id, title)\n",
    "                        elif ns == 0:\n",
    "                            if len(redirect) > 0:\n",
    "                                self.articleCount += 1\n",
    "                                self.worker.process_redirect(id, title, redirect)\n",
    "                            else:\n",
    "                                self.redirectCount += 1\n",
    "                                self.worker.process_article(id, title)\n",
    "\n",
    "                        title = \"\"\n",
    "                        redirect = \"\"\n",
    "                        ns = -100\n",
    "                        if self.totalCount > 1 and (self.totalCount % WORKER_REPORT) == 0:\n",
    "                            self.worker.report_progress(self.totalCount)\n",
    "                            self.totalCount = 0\n",
    "\n",
    "        elem.clear()\n",
    "        self.worker.report_progress(self.totalCount)\n",
    "        \n",
    "class ProcessPages():\n",
    "    def __init__(self, outputQueue):\n",
    "        self.templates = []\n",
    "        self.articles = []\n",
    "        self.redirects = []\n",
    "        self.outputQueue = outputQueue\n",
    "        \n",
    "    def process_template(self, id, title):\n",
    "        self.outputQueue.put(\n",
    "            {'template': [id, title] }\n",
    "        )\n",
    "    \n",
    "    def process_article(self, id, title):\n",
    "        self.outputQueue.put(\n",
    "            {'article': [id, title] }\n",
    "        )\n",
    "    \n",
    "    def process_redirect(self, id, title, redirect):\n",
    "        self.outputQueue.put(\n",
    "            {'redirect': [id, title, redirect] }\n",
    "        )\n",
    "        \n",
    "    def report_progress(self, completed):\n",
    "        self.outputQueue.put({\"completed\": completed})\n",
    "\n",
    "def worker2(inputQueue, outputQueue, config):\n",
    "    done = False\n",
    "    while not done:\n",
    "        path = inputQueue.get()\n",
    "        \n",
    "        if path == \"**exit**\":\n",
    "            done = True\n",
    "\n",
    "        try:\n",
    "            p = ProcessPages(outputQueue)\n",
    "            e = ExtractWikipedia(p)\n",
    "            e.extract_file(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            outputQueue.put({\"file_complete\":True})\n",
    "    \n",
    "ENCODING = \"utf-8\"\n",
    "\n",
    "TEST_FILE = 'enwiki-20201101-pages-meta-current9.xml-p2936261p4045402.bz2'\n",
    "TEST_PATH = os.path.join(WIKIPEDIA_DL, TEST_FILE)\n",
    "\n",
    "files = glob.glob(os.path.join(WIKIPEDIA_DL, \"*.bz2\"))\n",
    "print(f\"Processing {len(files)} files\")\n",
    "cpus = mp.cpu_count()\n",
    "print(f\"Detected {cpus} cores.\")\n",
    "workers = cpus * 1\n",
    "print(f\"Using {workers} threads\")\n",
    "\n",
    "inputQueue = mp.Queue()\n",
    "outputQueue = mp.Queue()\n",
    "config = {}\n",
    "\n",
    "for i in range(workers):\n",
    "    p = mp.Process(target=worker2, args=(inputQueue, outputQueue, config))\n",
    "    p.start()\n",
    "    \n",
    "for file in files:\n",
    "    inputQueue.put(file)\n",
    "    \n",
    "    \n",
    "pathArticles = os.path.join(WIKIPEDIA_ROOT, \"articles.csv\")\n",
    "pathRedirect = os.path.join(WIKIPEDIA_ROOT, \"redirect.csv\")\n",
    "pathTemplate = os.path.join(WIKIPEDIA_ROOT, \"template.csv\")\n",
    "    \n",
    "total_count = 0\n",
    "file_count = 0\n",
    "done = False\n",
    "while not done:\n",
    "    z = outputQueue.get()\n",
    "    if \"completed\" in z:\n",
    "        total_count += z[\"completed\"]\n",
    "        if total_count > 1 and (total_count % ENTIRE_TASK_REPORT) == 0:\n",
    "            print(f\"{total_count:,}, files: {file_count}\")\n",
    "    elif \"file_complete\" in z:\n",
    "        file_count += 1\n",
    "        if file_count()>=len(files):\n",
    "            print(\"done\")\n",
    "            done = True\n",
    "        \n",
    "        \n",
    "\n",
    "#\n",
    "#e = ExtractWikipedia(WIKIPEDIA_DL, p)\n",
    "#e.extract_file(TEST_PATH)\n",
    "#e.extract()\n",
    "#p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
